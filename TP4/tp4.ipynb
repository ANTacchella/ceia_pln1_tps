{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5a9c361",
      "metadata": {
        "id": "f5a9c361"
      },
      "source": [
        "TP4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown \"numpy<2.0\" torchinfo --quiet"
      ],
      "metadata": {
        "id": "FGmtK8J19PNk"
      },
      "execution_count": 27,
      "outputs": [],
      "id": "FGmtK8J19PNk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "from torchinfo import summary"
      ],
      "execution_count": 28,
      "outputs": [],
      "id": "cq3YXak9sGHd"
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYatMIdk_eT",
        "outputId": "025e38e4-f04e-4e8a-b039-211941212e10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "id": "vgYatMIdk_eT"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ],
      "metadata": {
        "id": "GHFPS5KNxgR9"
      },
      "execution_count": 30,
      "outputs": [],
      "id": "GHFPS5KNxgR9"
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_acc(y_pred, y_test):\n",
        "    y_pred_tag = y_pred.data.max(dim=-1,keepdim=True)[1]\n",
        "    y_test_tag = y_test.data.max(dim=-1,keepdim=True)[1]\n",
        "\n",
        "    batch_size = y_pred_tag.shape[0]\n",
        "    batch_acc = torch.zeros(batch_size)\n",
        "    for b in range(batch_size):\n",
        "        correct_results_sum = (y_pred_tag[b] == y_test_tag[b]).sum().float()\n",
        "        batch_acc[b] = correct_results_sum / y_pred_tag[b].shape[0]\n",
        "\n",
        "    correct_results_sum = batch_acc.sum().float()\n",
        "    acc = correct_results_sum / batch_size\n",
        "    return acc\n",
        "\n",
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
        "    # Defino listas para realizar graficas de los resultados\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    valid_loss = []\n",
        "    valid_accuracy = []\n",
        "\n",
        "    # Defino mi loop de entrenamiento\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        for train_encoder_input, train_decoder_input, train_target in train_loader:\n",
        "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
        "            # los va acumulando\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(train_encoder_input.to(device), train_decoder_input.to(device))\n",
        "\n",
        "            # Computo el error de la salida comparando contra las etiquetas\n",
        "            # por cada token en cada batch (sequence_loss)\n",
        "            loss = 0\n",
        "            for t in range(train_decoder_input.shape[1]):\n",
        "                loss += criterion(output[:, t, :], train_target[:, t, :])\n",
        "\n",
        "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
        "            loss.backward()\n",
        "\n",
        "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculo el accuracy del batch\n",
        "            accuracy = sequence_acc(output, train_target)\n",
        "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
        "            epoch_train_accuracy += accuracy.item()\n",
        "\n",
        "        # Calculo la media de error para la epoca de entrenamiento.\n",
        "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
        "        train_accuracy.append(epoch_train_accuracy)\n",
        "\n",
        "        # Realizo el paso de validación computando error y accuracy, y\n",
        "        # almacenando los valores para imprimirlos y graficarlos\n",
        "        valid_encoder_input, valid_decoder_input, valid_target = next(iter(valid_loader))\n",
        "        output = model(valid_encoder_input.to(device), valid_decoder_input.to(device))\n",
        "\n",
        "        epoch_valid_loss = 0\n",
        "        for t in range(train_decoder_input.shape[1]):\n",
        "                epoch_valid_loss += criterion(output[:, t, :], valid_target[:, t, :])\n",
        "        epoch_valid_loss = epoch_valid_loss.item()\n",
        "\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "\n",
        "        # Calculo el accuracy de la epoch\n",
        "        epoch_valid_accuracy = sequence_acc(output, valid_target).item()\n",
        "        valid_accuracy.append(epoch_valid_accuracy)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n",
        "\n",
        "    history = {\n",
        "        \"loss\": train_loss,\n",
        "        \"accuracy\": train_accuracy,\n",
        "        \"val_loss\": valid_loss,\n",
        "        \"val_accuracy\": valid_accuracy,\n",
        "    }\n",
        "    return history"
      ],
      "metadata": {
        "id": "tP-fbmHUgbtp"
      },
      "execution_count": 31,
      "outputs": [],
      "id": "tP-fbmHUgbtp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - Datos"
      ],
      "metadata": {
        "id": "5BFiCH8nxoIY"
      },
      "id": "5BFiCH8nxoIY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f12bfb4-68c5-4302-9ee2-9c3dd970c9db"
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('simpsons_dataset.zip', os.F_OK) is False:\n",
        "        url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "        output = 'spa-eng.zip'\n",
        "        gdown.download(url, output, quiet=False)\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ],
      "id": "RHNkUaPp6aYq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d59238c-826d-42c8-ef81-ebb500f9e21a"
      },
      "source": [
        "# dataset_file\n",
        "\n",
        "text_file = \"./spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# Por limitaciones de RAM no se leen todas las filas\n",
        "MAX_NUM_SENTENCES = 6000\n",
        "\n",
        "# Mezclar el dataset, forzar semilla siempre igual\n",
        "np.random.seed([40])\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "count = 0\n",
        "\n",
        "for line in lines:\n",
        "    count += 1\n",
        "    if count > MAX_NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "\n",
        "    # Input sentence --> eng\n",
        "    # output --> spa\n",
        "    input_sentence, output = line.rstrip().split('\\t')\n",
        "\n",
        "    # output sentence (decoder_output) tiene <eos>\n",
        "    output_sentence = output + ' <eos>'\n",
        "    # output sentence input (decoder_input) tiene <sos>\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows disponibles:\", len(lines))\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows disponibles: 118964\n",
            "Cantidad de rows utilizadas: 6000\n"
          ]
        }
      ],
      "id": "-9aNLZBDtA5J"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93IGMKFb73q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fadc943-3478-4309-9f1d-0d461cd9ff86"
      },
      "source": [
        "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('A deal is a deal.',\n",
              " 'Un trato es un trato. <eos>',\n",
              " '<sos> Un trato es un trato.')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "id": "93IGMKFb73q7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ],
      "id": "8P-ynUNP5xp6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WAZGOTfGyha"
      },
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 8000"
      ],
      "execution_count": 35,
      "outputs": [],
      "id": "5WAZGOTfGyha"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF1W6peoFGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c496d31f-c372-4a64-83fa-898ad274a158"
      },
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "from torch_helpers import Tokenizer\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 3851\n",
            "Sentencia de entrada más larga: 32\n"
          ]
        }
      ],
      "id": "eF1W6peoFGXA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzdKiTVIBYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3e3d7a-9248-413d-d4b9-c637be0100fc"
      },
      "source": [
        "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 5721\n",
            "Sentencia de salida más larga: 36\n"
          ]
        }
      ],
      "id": "zBzdKiTVIBYY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqb8ZJ4sJHgv"
      },
      "source": [
        "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
      ],
      "id": "Xqb8ZJ4sJHgv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgLC706EQx3p"
      },
      "source": [
        "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
        "# a la mitad:\n",
        "max_input_len = 16\n",
        "max_out_len = 18"
      ],
      "execution_count": 38,
      "outputs": [],
      "id": "pgLC706EQx3p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOn9N57IuYz"
      },
      "source": [
        "A la hora de realiza padding es importante teneer en cuenta que en el encoder los ceros se agregan al comienoz y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
      ],
      "id": "hGOn9N57IuYz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ob4hAWJkcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a023f3-d88f-45a0-fcb2-ee86e7642886"
      },
      "source": [
        "from torch_helpers import pad_sequences\n",
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows del dataset: 6000\n",
            "encoder_input_sequences shape: (6000, 16)\n",
            "decoder_input_sequences shape: (6000, 18)\n"
          ]
        }
      ],
      "id": "q0Ob4hAWJkcv"
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VySR1pzx9UG",
        "outputId": "a5cfa295-0545-4763-947b-b6b000f42557"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_output_sequences shape: (6000, 18)\n"
          ]
        }
      ],
      "id": "3VySR1pzx9UG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK4blEEsRQv3"
      },
      "source": [
        "La última capa del modelo (softmax) necesita que los valores de salida\n",
        "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
        "Se utiliza \"decoder_output_sequences\" con la misma estrategía que se transformó la entrada del decoder."
      ],
      "id": "wK4blEEsRQv3"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(decoder_output_sequences).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANTOqJ0WWw-q",
        "outputId": "eab599d9-9bfc-4801-b237-d5ced587b25d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6000, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "id": "ANTOqJ0WWw-q"
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
        "        # Convertir los arrays de numpy a tensores.\n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n",
        "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n",
        "        # Transformar los datos a oneHotEncoding\n",
        "        # la loss function esperan la salida float\n",
        "        self.decoder_outputs = F.one_hot(torch.from_numpy(decoder_output).to(torch.int64), num_classes=num_words_output).float()\n",
        "\n",
        "        self.len = self.decoder_outputs.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "output_dim = data_set.decoder_outputs.shape[2]\n",
        "print(\"Output dim\", output_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0bpM32yWfB",
        "outputId": "f03ff31e-bb21-47f5-ad49-3caaea93f94d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_size: 16\n",
            "decoder_input_size: 18\n",
            "Output dim 5722\n"
          ]
        }
      ],
      "id": "SD0bpM32yWfB"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUDPZeuAU1RI",
        "outputId": "c7e04e7f-ec4a-42e5-a798-b1fbeef7bdf7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 4800\n",
            "Tamaño del conjunto de validacion: 1200\n"
          ]
        }
      ],
      "id": "sUDPZeuAU1RI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings"
      ],
      "id": "_CJIsLBbj6rg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OcT-DLzkHS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0779f998-76ea-48e4-edd8-968cac27ec71"
      },
      "source": [
        "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los embeddings gloveembedding.pkl ya están descargados\n"
          ]
        }
      ],
      "id": "9OcT-DLzkHS8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "execution_count": 45,
      "outputs": [],
      "id": "ZgqtV8GpkSc8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK"
      },
      "source": [
        "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()"
      ],
      "execution_count": 46,
      "outputs": [],
      "id": "Mosj2-x-kXBK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f274e9c-0e12-4384-ec25-b908f0e16813"
      },
      "source": [
        "# Crear la Embedding matrix de las secuencias\n",
        "# en ingles\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 30\n"
          ]
        }
      ],
      "id": "b9FS8ca1ke_B"
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3U_WmEYRdH",
        "outputId": "453d0858-9bae-4418-e70b-03b29e70b606"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3851"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "id": "4q3U_WmEYRdH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpzJODHBlAtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8189f0-da74-4c38-be4f-e2036cd1ebbc"
      },
      "source": [
        "# Dimensión de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3851, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "id": "FpzJODHBlAtE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ],
      "id": "3vKbhjtIwPgM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fm3HCLMPSG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13465fff-4ca7-4f36-b034-917c0b8fbba0"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers) # LSTM layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out)\n",
        "        return (ht, ct)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim):\n",
        "        super().__init__()\n",
        "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
        "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
        "                            num_layers=self.num_layers) # LSTM layer\n",
        "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim) # Fully connected layer\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        out = self.softmax(self.fc1(lstm_output[:,-1,:])) # take last output (last seq)\n",
        "        return out, (ht, ct)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        assert encoder.lstm_size == decoder.lstm_size, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.num_layers == decoder.num_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        batch_size = decoder_input.shape[0]\n",
        "        decoder_input_len = decoder_input.shape[1]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # tensor para almacenar la salida\n",
        "        # (batch_size, sentence_len, one_hot_size)\n",
        "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size)\n",
        "\n",
        "        # ultimo hidden state del encoder, primer estado oculto del decoder\n",
        "        prev_state = self.encoder(encoder_input)\n",
        "\n",
        "        # En la primera iteracion se toma el primer token de target (<sos>)\n",
        "        input = decoder_input[:, 0:1]\n",
        "\n",
        "        for t in range(decoder_input_len):\n",
        "            # t --> token index\n",
        "\n",
        "            # utilizamos método \"teacher forcing\", es decir que durante\n",
        "            # el entrenamiento no realimentamos la salida del decoder\n",
        "            # sino el token correcto que sigue en target\n",
        "            input = decoder_input[:, t:t+1]\n",
        "\n",
        "            # ingresar cada token embedding, uno por uno junto al hidden state\n",
        "            # recibir el output del decoder (softmax)\n",
        "            output, prev_state = self.decoder(input, prev_state)\n",
        "            top1 = output.argmax(1).view(-1, 1)\n",
        "\n",
        "            # Sino se usará \"teacher forcing\" habría que descomentar\n",
        "            # esta linea.\n",
        "            # Hay ejemplos dandos vuelta en donde se utilza un random\n",
        "            # para ver en cada vuelta que técnica se aplica\n",
        "            #input = top1\n",
        "\n",
        "            # guardar cada salida (softmax)\n",
        "            outputs[:, t, :] = output\n",
        "\n",
        "        return outputs\n",
        "\n",
        "encoder = Encoder(vocab_size=nb_words)\n",
        "if cuda: encoder.cuda()\n",
        "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
        "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "if cuda: decoder.cuda()\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "if cuda: model.cuda()\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "# Move input data to the device before passing it to summary\n",
        "sample_encoder_input, sample_decoder_input, _ = data_set[0:1]\n",
        "summary(model, input_data=(sample_encoder_input.to(device), sample_decoder_input.to(device)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Seq2Seq                                  [1, 18, 5722]             --\n",
              "├─Encoder: 1-1                           [1, 1, 128]               --\n",
              "│    └─Embedding: 2-1                    [1, 16, 50]               (192,550)\n",
              "│    └─LSTM: 2-2                         [1, 16, 128]              92,160\n",
              "├─Decoder: 1-2                           [1, 5722]                 --\n",
              "│    └─Embedding: 2-3                    [1, 1, 50]                286,100\n",
              "│    └─LSTM: 2-4                         [1, 1, 128]               92,160\n",
              "│    └─Linear: 2-5                       [1, 5722]                 738,138\n",
              "│    └─Softmax: 2-6                      [1, 5722]                 --\n",
              "├─Decoder: 1-3                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-7                    [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-8                         [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-9                       [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-10                     [1, 5722]                 --\n",
              "├─Decoder: 1-4                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-11                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-12                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-13                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-14                     [1, 5722]                 --\n",
              "├─Decoder: 1-5                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-15                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-16                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-17                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-18                     [1, 5722]                 --\n",
              "├─Decoder: 1-6                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-19                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-20                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-21                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-22                     [1, 5722]                 --\n",
              "├─Decoder: 1-7                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-23                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-24                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-25                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-26                     [1, 5722]                 --\n",
              "├─Decoder: 1-8                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-27                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-28                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-29                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-30                     [1, 5722]                 --\n",
              "├─Decoder: 1-9                           [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-31                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-32                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-33                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-34                     [1, 5722]                 --\n",
              "├─Decoder: 1-10                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-35                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-36                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-37                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-38                     [1, 5722]                 --\n",
              "├─Decoder: 1-11                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-39                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-40                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-41                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-42                     [1, 5722]                 --\n",
              "├─Decoder: 1-12                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-43                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-44                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-45                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-46                     [1, 5722]                 --\n",
              "├─Decoder: 1-13                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-47                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-48                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-49                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-50                     [1, 5722]                 --\n",
              "├─Decoder: 1-14                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-51                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-52                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-53                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-54                     [1, 5722]                 --\n",
              "├─Decoder: 1-15                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-55                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-56                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-57                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-58                     [1, 5722]                 --\n",
              "├─Decoder: 1-16                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-59                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-60                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-61                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-62                     [1, 5722]                 --\n",
              "├─Decoder: 1-17                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-63                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-64                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-65                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-66                     [1, 5722]                 --\n",
              "├─Decoder: 1-18                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-67                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-68                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-69                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-70                     [1, 5722]                 --\n",
              "├─Decoder: 1-19                          [1, 5722]                 (recursive)\n",
              "│    └─Embedding: 2-71                   [1, 1, 50]                (recursive)\n",
              "│    └─LSTM: 2-72                        [1, 1, 128]               (recursive)\n",
              "│    └─Linear: 2-73                      [1, 5722]                 (recursive)\n",
              "│    └─Softmax: 2-74                     [1, 5722]                 --\n",
              "==========================================================================================\n",
              "Total params: 1,401,108\n",
              "Trainable params: 1,208,558\n",
              "Non-trainable params: 192,550\n",
              "Total mult-adds (Units.MEGABYTES): 21.76\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.87\n",
              "Params size (MB): 5.60\n",
              "Estimated Total Size (MB): 6.48\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "id": "3fm3HCLMPSG-"
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = train(model,\n",
        "                train_loader,\n",
        "                valid_loader,\n",
        "                optimizer,\n",
        "                criterion,\n",
        "                epochs=10\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDB0KWIegt8s",
        "outputId": "1232f786-87ed-4f91-ddb9-377889f8e6e2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10 - Train loss 144.842 - Train accuracy 0.606 - Valid Loss 144.899 - Valid accuracy 0.602\n",
            "Epoch: 2/10 - Train loss 144.730 - Train accuracy 0.612 - Valid Loss 144.836 - Valid accuracy 0.606\n",
            "Epoch: 3/10 - Train loss 144.573 - Train accuracy 0.621 - Valid Loss 144.374 - Valid accuracy 0.634\n",
            "Epoch: 4/10 - Train loss 143.961 - Train accuracy 0.655 - Valid Loss 144.156 - Valid accuracy 0.644\n",
            "Epoch: 5/10 - Train loss 143.828 - Train accuracy 0.662 - Valid Loss 144.078 - Valid accuracy 0.648\n",
            "Epoch: 6/10 - Train loss 143.781 - Train accuracy 0.665 - Valid Loss 143.993 - Valid accuracy 0.653\n",
            "Epoch: 7/10 - Train loss 143.768 - Train accuracy 0.665 - Valid Loss 143.995 - Valid accuracy 0.653\n",
            "Epoch: 8/10 - Train loss 143.763 - Train accuracy 0.666 - Valid Loss 144.023 - Valid accuracy 0.653\n",
            "Epoch: 9/10 - Train loss 143.755 - Train accuracy 0.666 - Valid Loss 144.014 - Valid accuracy 0.651\n",
            "Epoch: 10/10 - Train loss 143.754 - Train accuracy 0.666 - Valid Loss 144.086 - Valid accuracy 0.648\n"
          ]
        }
      ],
      "id": "VDB0KWIegt8s"
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history1['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pZzm3tx059Zv",
        "outputId": "7941d3ba-5779-483c-f8dc-97366c348350"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "id": "pZzm3tx059Zv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ],
      "id": "Zbwn0ekDy_s2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnkl3mSpsU_7"
      },
      "source": [
        "'''\n",
        "Step 1:\n",
        "A deal is a deal -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
        "\n",
        "step 2:\n",
        "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
        "\n",
        "step 3:\n",
        "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
        "\n",
        "step 4:\n",
        "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
        "\n",
        "step 5:\n",
        "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
        "\n",
        "step 6:\n",
        "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "jnkl3mSpsU_7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71XeCtfYmOFx"
      },
      "source": [
        "# Armar lo conversores de indice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 54,
      "outputs": [],
      "id": "71XeCtfYmOFx"
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"My mother say hi.\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
        "\n",
        "# Se obtiene la salida del encoder (el estado oculto para el decoder)\n",
        "prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
        "\n",
        "# Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "target_seq = np.zeros((1, 1))\n",
        "target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
        "\n",
        "# Se obtiene la primera palabra de la secuencia de salida del decoder\n",
        "output, prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
        "\n",
        "top1 = output.argmax(1).view(-1, 1)\n",
        "idx = int(top1.cpu())\n",
        "print(\"Index/token de salida:\", idx)\n",
        "\n",
        "word = idx2word_target[idx]\n",
        "print(\"Palabra de salida:\", word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YOZFX8WkHsQ",
        "outputId": "3dfb830a-66cd-49a5-96c2-a19f859ffd22"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: My mother say hi.\n",
            "Representacion en vector de tokens de ids [15, 225, 134]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0  15 225 134]]\n",
            "Index/token de salida: 6\n",
            "Palabra de salida: tom\n"
          ]
        }
      ],
      "id": "-YOZFX8WkHsQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlUyp9M6ua2V"
      },
      "source": [
        "def translate_sentence(input_seq):\n",
        "    # Se transforma la sequencia de entrada a los stados \"h\" y \"c\" de la LSTM\n",
        "    # para enviar la primera vez al decoder\"\n",
        "    prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
        "\n",
        "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
        "\n",
        "    # Se obtiene el indice que finaliza la inferencia\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "\n",
        "    output_sentence = []\n",
        "    for _ in range(max_out_len):\n",
        "        # Predicción del próximo elemento\n",
        "        output, new_prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
        "        top1 = output.argmax(1).view(-1, 1)\n",
        "        idx = int(top1.cpu())\n",
        "\n",
        "        # Si es \"end of sentece <eos>\" se acaba\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        # Transformar ídx a palabra\n",
        "        word = ''\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados dado la ultimo prediccion\n",
        "        prev_state = new_prev_state\n",
        "\n",
        "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
        "        target_seq_tensor = top1\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "execution_count": 56,
      "outputs": [],
      "id": "MlUyp9M6ua2V"
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"My mother say hi.\"\n",
        "print('Input:', input_test)\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
        "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "print(\"Padding del vector:\", encoder_sequence_test)\n",
        "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
        "\n",
        "translation = translate_sentence(encoder_sequence_test)\n",
        "print('Response:', translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd6VJcZb9It_",
        "outputId": "1f8b618f-c4d7-473e-dbc0-da0f9629d00a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: My mother say hi.\n",
            "Representacion en vector de tokens de ids [15, 225, 134]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0  15 225 134]]\n",
            "Response: tom\n"
          ]
        }
      ],
      "id": "Fd6VJcZb9It_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhGVjLKcunxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942084fd-3b37-4da6-88f8-45c75ea60481"
      },
      "source": [
        "i = np.random.choice(len(input_sentences))\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
        "translation = translate_sentence(encoder_sequence_test_tensor)\n",
        "print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input: Mary wants to buy a dress.\n",
            "Response: tom\n"
          ]
        }
      ],
      "id": "ZhGVjLKcunxW"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}